[2018-11-14 21:59:37,990]   >> MwAN(
  (embedding): Embedding(96973, 200)
  (q_encoder): GRU(200, 256, batch_first=True, bidirectional=True)
  (p_encoder): GRU(205, 256, batch_first=True, bidirectional=True)
  (a_encoder): GRU(200, 100, batch_first=True, bidirectional=True)
  (a_attention): Linear(in_features=200, out_features=1, bias=False)
  (att_attention): Linear(in_features=512, out_features=1, bias=True)
  (Wc1): Linear(in_features=512, out_features=256, bias=False)
  (Wc2): Linear(in_features=512, out_features=256, bias=False)
  (vc): Linear(in_features=256, out_features=1, bias=False)
  (Wb): Linear(in_features=512, out_features=512, bias=False)
  (Wd): Linear(in_features=512, out_features=256, bias=False)
  (vd): Linear(in_features=256, out_features=1, bias=False)
  (Wm): Linear(in_features=512, out_features=256, bias=False)
  (vm): Linear(in_features=256, out_features=1, bias=False)
  (Ws): Linear(in_features=512, out_features=256, bias=False)
  (vs): Linear(in_features=256, out_features=1, bias=False)
  (Wqa1): Linear(in_features=512, out_features=1, bias=False)
  (Wqa2): Linear(in_features=512, out_features=1, bias=False)
  (Wqa3): Linear(in_features=512, out_features=512, bias=False)
  (gru_agg): GRU(512, 256, batch_first=True, bidirectional=True)
  (Wq): Linear(in_features=512, out_features=256, bias=False)
  (vq): Linear(in_features=256, out_features=1, bias=False)
  (Wp1): Linear(in_features=512, out_features=256, bias=False)
  (Wp2): Linear(in_features=512, out_features=256, bias=False)
  (vp): Linear(in_features=256, out_features=1, bias=False)
  (prediction): Linear(in_features=512, out_features=200, bias=False)
)
[2018-11-14 21:59:37,991]   >> path to save the model model.pt
[2018-11-14 22:02:35,708]   >> MwAN(
  (embedding): Embedding(96973, 200)
  (q_encoder): GRU(200, 256, batch_first=True, bidirectional=True)
  (p_encoder): GRU(205, 256, batch_first=True, bidirectional=True)
  (a_encoder): GRU(200, 100, batch_first=True, bidirectional=True)
  (a_attention): Linear(in_features=200, out_features=1, bias=False)
  (att_attention): Linear(in_features=512, out_features=1, bias=True)
  (Wc1): Linear(in_features=512, out_features=256, bias=False)
  (Wc2): Linear(in_features=512, out_features=256, bias=False)
  (vc): Linear(in_features=256, out_features=1, bias=False)
  (Wb): Linear(in_features=512, out_features=512, bias=False)
  (Wd): Linear(in_features=512, out_features=256, bias=False)
  (vd): Linear(in_features=256, out_features=1, bias=False)
  (Wm): Linear(in_features=512, out_features=256, bias=False)
  (vm): Linear(in_features=256, out_features=1, bias=False)
  (Ws): Linear(in_features=512, out_features=256, bias=False)
  (vs): Linear(in_features=256, out_features=1, bias=False)
  (Wqa1): Linear(in_features=512, out_features=1, bias=False)
  (Wqa2): Linear(in_features=512, out_features=1, bias=False)
  (Wqa3): Linear(in_features=512, out_features=512, bias=False)
  (gru_agg): GRU(512, 256, batch_first=True, bidirectional=True)
  (Wq): Linear(in_features=512, out_features=256, bias=False)
  (vq): Linear(in_features=256, out_features=1, bias=False)
  (Wp1): Linear(in_features=512, out_features=256, bias=False)
  (Wp2): Linear(in_features=512, out_features=256, bias=False)
  (vp): Linear(in_features=256, out_features=1, bias=False)
  (prediction): Linear(in_features=512, out_features=200, bias=False)
)
[2018-11-14 22:02:35,709]   >> path to save the model model.pt
[2018-11-14 22:02:45,481]   >> train data size 250000, dev data size 6
[2018-11-14 22:04:06,823]   >> MwAN(
  (embedding): Embedding(96973, 200)
  (q_encoder): GRU(200, 256, batch_first=True, bidirectional=True)
  (p_encoder): GRU(205, 256, batch_first=True, bidirectional=True)
  (a_encoder): GRU(200, 100, batch_first=True, bidirectional=True)
  (a_attention): Linear(in_features=200, out_features=1, bias=False)
  (att_attention): Linear(in_features=512, out_features=1, bias=True)
  (Wc1): Linear(in_features=512, out_features=256, bias=False)
  (Wc2): Linear(in_features=512, out_features=256, bias=False)
  (vc): Linear(in_features=256, out_features=1, bias=False)
  (Wb): Linear(in_features=512, out_features=512, bias=False)
  (Wd): Linear(in_features=512, out_features=256, bias=False)
  (vd): Linear(in_features=256, out_features=1, bias=False)
  (Wm): Linear(in_features=512, out_features=256, bias=False)
  (vm): Linear(in_features=256, out_features=1, bias=False)
  (Ws): Linear(in_features=512, out_features=256, bias=False)
  (vs): Linear(in_features=256, out_features=1, bias=False)
  (Wqa1): Linear(in_features=512, out_features=1, bias=False)
  (Wqa2): Linear(in_features=512, out_features=1, bias=False)
  (Wqa3): Linear(in_features=512, out_features=512, bias=False)
  (gru_agg): GRU(512, 256, batch_first=True, bidirectional=True)
  (Wq): Linear(in_features=512, out_features=256, bias=False)
  (vq): Linear(in_features=256, out_features=1, bias=False)
  (Wp1): Linear(in_features=512, out_features=256, bias=False)
  (Wp2): Linear(in_features=512, out_features=256, bias=False)
  (vp): Linear(in_features=256, out_features=1, bias=False)
  (prediction): Linear(in_features=512, out_features=200, bias=False)
)
[2018-11-14 22:04:06,824]   >> path to save the model model.pt
[2018-11-14 22:04:16,641]   >> train data size 250000, dev data size 6
[2018-11-14 22:05:10,754]   >> MwAN(
  (embedding): Embedding(96973, 200)
  (q_encoder): GRU(200, 256, batch_first=True, bidirectional=True)
  (p_encoder): GRU(205, 256, batch_first=True, bidirectional=True)
  (a_encoder): GRU(200, 100, batch_first=True, bidirectional=True)
  (a_attention): Linear(in_features=200, out_features=1, bias=False)
  (att_attention): Linear(in_features=512, out_features=1, bias=True)
  (Wc1): Linear(in_features=512, out_features=256, bias=False)
  (Wc2): Linear(in_features=512, out_features=256, bias=False)
  (vc): Linear(in_features=256, out_features=1, bias=False)
  (Wb): Linear(in_features=512, out_features=512, bias=False)
  (Wd): Linear(in_features=512, out_features=256, bias=False)
  (vd): Linear(in_features=256, out_features=1, bias=False)
  (Wm): Linear(in_features=512, out_features=256, bias=False)
  (vm): Linear(in_features=256, out_features=1, bias=False)
  (Ws): Linear(in_features=512, out_features=256, bias=False)
  (vs): Linear(in_features=256, out_features=1, bias=False)
  (Wqa1): Linear(in_features=512, out_features=1, bias=False)
  (Wqa2): Linear(in_features=512, out_features=1, bias=False)
  (Wqa3): Linear(in_features=512, out_features=512, bias=False)
  (gru_agg): GRU(512, 256, batch_first=True, bidirectional=True)
  (Wq): Linear(in_features=512, out_features=256, bias=False)
  (vq): Linear(in_features=256, out_features=1, bias=False)
  (Wp1): Linear(in_features=512, out_features=256, bias=False)
  (Wp2): Linear(in_features=512, out_features=256, bias=False)
  (vp): Linear(in_features=256, out_features=1, bias=False)
  (prediction): Linear(in_features=512, out_features=200, bias=False)
)
[2018-11-14 22:05:10,755]   >> path to save the model model.pt
[2018-11-14 22:05:20,977]   >> train data size 250000, dev data size 6
[2018-11-14 22:08:15,222]   >> MwAN(
  (embedding): Embedding(96973, 200)
  (q_encoder): GRU(200, 256, batch_first=True, bidirectional=True)
  (p_encoder): GRU(205, 256, batch_first=True, bidirectional=True)
  (a_encoder): GRU(200, 100, batch_first=True, bidirectional=True)
  (a_attention): Linear(in_features=200, out_features=1, bias=False)
  (att_attention): Linear(in_features=512, out_features=1, bias=True)
  (Wc1): Linear(in_features=512, out_features=256, bias=False)
  (Wc2): Linear(in_features=512, out_features=256, bias=False)
  (vc): Linear(in_features=256, out_features=1, bias=False)
  (Wb): Linear(in_features=512, out_features=512, bias=False)
  (Wd): Linear(in_features=512, out_features=256, bias=False)
  (vd): Linear(in_features=256, out_features=1, bias=False)
  (Wm): Linear(in_features=512, out_features=256, bias=False)
  (vm): Linear(in_features=256, out_features=1, bias=False)
  (Ws): Linear(in_features=512, out_features=256, bias=False)
  (vs): Linear(in_features=256, out_features=1, bias=False)
  (Wqa1): Linear(in_features=512, out_features=1, bias=False)
  (Wqa2): Linear(in_features=512, out_features=1, bias=False)
  (Wqa3): Linear(in_features=512, out_features=512, bias=False)
  (gru_agg): GRU(512, 256, batch_first=True, bidirectional=True)
  (Wq): Linear(in_features=512, out_features=256, bias=False)
  (vq): Linear(in_features=256, out_features=1, bias=False)
  (Wp1): Linear(in_features=512, out_features=256, bias=False)
  (Wp2): Linear(in_features=512, out_features=256, bias=False)
  (vp): Linear(in_features=256, out_features=1, bias=False)
  (prediction): Linear(in_features=512, out_features=200, bias=False)
)
[2018-11-14 22:08:15,223]   >> path to save the model model.pt
[2018-11-14 22:08:24,826]   >> train data size 250000, dev data size 6
[2018-11-14 22:09:09,992]   >> MwAN(
  (embedding): Embedding(96973, 200)
  (q_encoder): GRU(200, 256, batch_first=True, bidirectional=True)
  (p_encoder): GRU(205, 256, batch_first=True, bidirectional=True)
  (a_encoder): GRU(200, 100, batch_first=True, bidirectional=True)
  (a_attention): Linear(in_features=200, out_features=1, bias=False)
  (att_attention): Linear(in_features=512, out_features=1, bias=True)
  (Wc1): Linear(in_features=512, out_features=256, bias=False)
  (Wc2): Linear(in_features=512, out_features=256, bias=False)
  (vc): Linear(in_features=256, out_features=1, bias=False)
  (Wb): Linear(in_features=512, out_features=512, bias=False)
  (Wd): Linear(in_features=512, out_features=256, bias=False)
  (vd): Linear(in_features=256, out_features=1, bias=False)
  (Wm): Linear(in_features=512, out_features=256, bias=False)
  (vm): Linear(in_features=256, out_features=1, bias=False)
  (Ws): Linear(in_features=512, out_features=256, bias=False)
  (vs): Linear(in_features=256, out_features=1, bias=False)
  (Wqa1): Linear(in_features=512, out_features=1, bias=False)
  (Wqa2): Linear(in_features=512, out_features=1, bias=False)
  (Wqa3): Linear(in_features=512, out_features=512, bias=False)
  (gru_agg): GRU(512, 256, batch_first=True, bidirectional=True)
  (Wq): Linear(in_features=512, out_features=256, bias=False)
  (vq): Linear(in_features=256, out_features=1, bias=False)
  (Wp1): Linear(in_features=512, out_features=256, bias=False)
  (Wp2): Linear(in_features=512, out_features=256, bias=False)
  (vp): Linear(in_features=256, out_features=1, bias=False)
  (prediction): Linear(in_features=512, out_features=200, bias=False)
)
[2018-11-14 22:09:09,993]   >> path to save the model model.pt
[2018-11-14 22:09:19,782]   >> train data size 250000, dev data size 6
[2018-11-14 22:10:17,268]   >> MwAN(
  (embedding): Embedding(96973, 200)
  (q_encoder): GRU(200, 256, batch_first=True, bidirectional=True)
  (p_encoder): GRU(205, 256, batch_first=True, bidirectional=True)
  (a_encoder): GRU(200, 100, batch_first=True, bidirectional=True)
  (a_attention): Linear(in_features=200, out_features=1, bias=False)
  (att_attention): Linear(in_features=512, out_features=1, bias=True)
  (Wc1): Linear(in_features=512, out_features=256, bias=False)
  (Wc2): Linear(in_features=512, out_features=256, bias=False)
  (vc): Linear(in_features=256, out_features=1, bias=False)
  (Wb): Linear(in_features=512, out_features=512, bias=False)
  (Wd): Linear(in_features=512, out_features=256, bias=False)
  (vd): Linear(in_features=256, out_features=1, bias=False)
  (Wm): Linear(in_features=512, out_features=256, bias=False)
  (vm): Linear(in_features=256, out_features=1, bias=False)
  (Ws): Linear(in_features=512, out_features=256, bias=False)
  (vs): Linear(in_features=256, out_features=1, bias=False)
  (Wqa1): Linear(in_features=512, out_features=1, bias=False)
  (Wqa2): Linear(in_features=512, out_features=1, bias=False)
  (Wqa3): Linear(in_features=512, out_features=512, bias=False)
  (gru_agg): GRU(512, 256, batch_first=True, bidirectional=True)
  (Wq): Linear(in_features=512, out_features=256, bias=False)
  (vq): Linear(in_features=256, out_features=1, bias=False)
  (Wp1): Linear(in_features=512, out_features=256, bias=False)
  (Wp2): Linear(in_features=512, out_features=256, bias=False)
  (vp): Linear(in_features=256, out_features=1, bias=False)
  (prediction): Linear(in_features=512, out_features=200, bias=False)
)
[2018-11-14 22:10:17,269]   >> path to save the model model.pt
[2018-11-14 22:10:27,384]   >> train data size 250000, dev data size 6
[2018-11-14 22:11:09,855]   >> |---epoch 0 train error is 0.916383  acc is 57.322917  eclipse 3.83%---|
[2018-11-14 22:11:47,811]   >> |---epoch 0 train error is 0.812794  acc is 61.177083  eclipse 7.67%---|
[2018-11-14 22:14:22,082]   >> MwAN(
  (embedding): Embedding(96973, 200)
  (q_encoder): GRU(200, 256, batch_first=True, bidirectional=True)
  (p_encoder): GRU(205, 256, batch_first=True, bidirectional=True)
  (a_encoder): GRU(200, 100, batch_first=True, bidirectional=True)
  (a_attention): Linear(in_features=200, out_features=1, bias=False)
  (att_attention): Linear(in_features=512, out_features=1, bias=True)
  (Wc1): Linear(in_features=512, out_features=256, bias=False)
  (Wc2): Linear(in_features=512, out_features=256, bias=False)
  (vc): Linear(in_features=256, out_features=1, bias=False)
  (Wb): Linear(in_features=512, out_features=512, bias=False)
  (Wd): Linear(in_features=512, out_features=256, bias=False)
  (vd): Linear(in_features=256, out_features=1, bias=False)
  (Wm): Linear(in_features=512, out_features=256, bias=False)
  (vm): Linear(in_features=256, out_features=1, bias=False)
  (Ws): Linear(in_features=512, out_features=256, bias=False)
  (vs): Linear(in_features=256, out_features=1, bias=False)
  (Wqa1): Linear(in_features=512, out_features=1, bias=False)
  (Wqa2): Linear(in_features=512, out_features=1, bias=False)
  (Wqa3): Linear(in_features=512, out_features=512, bias=False)
  (gru_agg): GRU(512, 256, batch_first=True, bidirectional=True)
  (Wq): Linear(in_features=512, out_features=256, bias=False)
  (vq): Linear(in_features=256, out_features=1, bias=False)
  (Wp1): Linear(in_features=512, out_features=256, bias=False)
  (Wp2): Linear(in_features=512, out_features=256, bias=False)
  (vp): Linear(in_features=256, out_features=1, bias=False)
  (prediction): Linear(in_features=512, out_features=200, bias=False)
)
[2018-11-14 22:14:22,082]   >> path to save the model model.pt
[2018-11-14 22:14:32,265]   >> train data size 250000, dev data size 6
[2018-11-14 22:16:19,110]   >> MwAN(
  (embedding): Embedding(96973, 200)
  (q_encoder): GRU(200, 256, batch_first=True, bidirectional=True)
  (p_encoder): GRU(205, 256, batch_first=True, bidirectional=True)
  (a_encoder): GRU(200, 100, batch_first=True, bidirectional=True)
  (a_attention): Linear(in_features=200, out_features=1, bias=False)
  (att_attention): Linear(in_features=512, out_features=1, bias=True)
  (Wc1): Linear(in_features=512, out_features=256, bias=False)
  (Wc2): Linear(in_features=512, out_features=256, bias=False)
  (vc): Linear(in_features=256, out_features=1, bias=False)
  (Wb): Linear(in_features=512, out_features=512, bias=False)
  (Wd): Linear(in_features=512, out_features=256, bias=False)
  (vd): Linear(in_features=256, out_features=1, bias=False)
  (Wm): Linear(in_features=512, out_features=256, bias=False)
  (vm): Linear(in_features=256, out_features=1, bias=False)
  (Ws): Linear(in_features=512, out_features=256, bias=False)
  (vs): Linear(in_features=256, out_features=1, bias=False)
  (Wqa1): Linear(in_features=512, out_features=1, bias=False)
  (Wqa2): Linear(in_features=512, out_features=1, bias=False)
  (Wqa3): Linear(in_features=512, out_features=512, bias=False)
  (gru_agg): GRU(512, 256, batch_first=True, bidirectional=True)
  (Wq): Linear(in_features=512, out_features=256, bias=False)
  (vq): Linear(in_features=256, out_features=1, bias=False)
  (Wp1): Linear(in_features=512, out_features=256, bias=False)
  (Wp2): Linear(in_features=512, out_features=256, bias=False)
  (vp): Linear(in_features=256, out_features=1, bias=False)
  (prediction): Linear(in_features=512, out_features=200, bias=False)
)
[2018-11-14 22:16:19,111]   >> path to save the model model.pt
[2018-11-14 22:16:28,664]   >> train data size 250000, dev data size 6
[2018-11-14 22:17:16,099]   >> |---epoch 0 train error is 0.926748  acc is 57.822917  eclipse 3.83%---|
[2018-11-14 22:17:58,894]   >> |---epoch 0 train error is 0.748997  acc is 62.187500  eclipse 7.67%---|
[2018-11-14 22:17:59,727]   >> |------epoch 0 eclipse 7.667200 validation acc 50.000000
